{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a0fd4-3dde-4acb-a802-8682d91de8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, TimestampType\n",
    "from pyspark.sql.functions import from_json, col, window, to_timestamp\n",
    "import time\n",
    "\n",
    "# Initialize Spark Session with more configurations\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ClimateWatch Streaming\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\") \\\n",
    "    .config(\"spark.streaming.stopGracefullyOnShutdown\", \"true\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"1\") \\\n",
    "    .config(\"spark.default.parallelism\", \"1\") \\\n",
    "    .config(\"spark.streaming.kafka.consumer.cache.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to see more details\n",
    "spark.sparkContext.setLogLevel(\"DEBUG\")\n",
    "\n",
    "# Define schema for climate data\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"temperature\", FloatType(), True),\n",
    "    StructField(\"humidity\", FloatType(), True),\n",
    "    StructField(\"wind_speed\", FloatType(), True),\n",
    "    StructField(\"precipitation\", FloatType(), True),\n",
    "    StructField(\"pressure\", FloatType(), True),\n",
    "    StructField(\"snow\", FloatType(), True)\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Kafka'dan veri okumaya başlıyorum...\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Read streaming data from Kafka with more options\n",
    "stream_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"climate-data\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .option(\"kafka.security.protocol\", \"PLAINTEXT\") \\\n",
    "    .option(\"kafka.request.timeout.ms\", \"60000\") \\\n",
    "    .option(\"kafka.session.timeout.ms\", \"60000\") \\\n",
    "    .option(\"fetchOffset.numRetries\", \"5\") \\\n",
    "    .option(\"maxOffsetsPerTrigger\", \"200\") \\\n",
    "    .load()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Kafka bağlantısı kuruldu.\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Add some debug information\n",
    "print(\"Kafka Stream Schema:\")\n",
    "stream_df.printSchema()\n",
    "\n",
    "# Parse JSON data and convert timestamp\n",
    "parsed = stream_df.select(\n",
    "    from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\")\n",
    ").select(\"data.*\") \\\n",
    ".withColumn(\"event_time\", to_timestamp(col(\"timestamp\")))\n",
    "\n",
    "print(\"\\nParsed Data Schema:\")\n",
    "parsed.printSchema()\n",
    "\n",
    "# Analyze data in 5-minute windows\n",
    "windowed_stats = parsed \\\n",
    "    .withWatermark(\"event_time\", \"10 minutes\") \\\n",
    "    .groupBy(\n",
    "        window(\"event_time\", \"5 minutes\"),\n",
    "        \"location\"\n",
    "    ) \\\n",
    "    .agg({\n",
    "        \"temperature\": \"avg\",\n",
    "        \"humidity\": \"avg\",\n",
    "        \"precipitation\": \"sum\",\n",
    "        \"wind_speed\": \"avg\",\n",
    "        \"pressure\": \"avg\",\n",
    "        \"snow\": \"sum\"\n",
    "    })\n",
    "\n",
    "# Format results with more readable column names\n",
    "formatted_stats = windowed_stats.select(\n",
    "    col(\"window.start\").alias(\"window_start\"),\n",
    "    col(\"window.end\").alias(\"window_end\"),\n",
    "    col(\"location\"),\n",
    "    col(\"avg(temperature)\").cast(\"decimal(10,2)\").alias(\"avg_temp_celsius\"),\n",
    "    col(\"avg(humidity)\").cast(\"decimal(10,2)\").alias(\"avg_humidity_percent\"),\n",
    "    col(\"sum(precipitation)\").cast(\"decimal(10,2)\").alias(\"total_precipitation_mm\"),\n",
    "    col(\"avg(wind_speed)\").cast(\"decimal(10,2)\").alias(\"avg_wind_speed_kmh\"),\n",
    "    col(\"avg(pressure)\").cast(\"decimal(10,2)\").alias(\"avg_pressure_hpa\"),\n",
    "    col(\"sum(snow)\").cast(\"decimal(10,2)\").alias(\"total_snow_mm\")\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Stream işleme başlıyor...\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Write results to console with more visible formatting\n",
    "query = formatted_stats \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .option(\"numRows\", 100) \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Stream başlatıldı, veriler gelmeye başlayacak...\")\n",
    "print(\"Aktif streaming sorgularının sayısı:\", len(spark.streams.active))\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    # Monitor the query status\n",
    "    while query.isActive:\n",
    "        print(f\"\\nSorgu durumu: {query.status}\")\n",
    "        print(f\"Son işleme zamanı: {query.lastProgress}\")\n",
    "        time.sleep(5)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nUygulama kullanıcı tarafından durduruldu.\")\n",
    "    query.stop()\n",
    "except Exception as e:\n",
    "    print(f\"\\nBir hata oluştu: {str(e)}\")\n",
    "    query.stop()\n",
    "finally:\n",
    "    # Keep the streaming query running\n",
    "    query.awaitTermination() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c232273-b1ff-4beb-8ae3-f3e805c40425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63af359-1018-4233-9a5b-ee01587eacb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
